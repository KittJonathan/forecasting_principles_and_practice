---
title: "3. Time series decomposition"
format: html
editor: visual
execute: 
  echo: true
  eval: true
---

```{r}
library(fpp3)
```

We can think of a time series as comprising three components:

-   a trend-cycle component

-   a seasonal component

-   a remainder component (containing anything else in the time series)

# 3.1 Transformations and adjustments

Per capita adjustments

```{r}
global_economy |> 
  filter(Country == "Australia") |> 
  autoplot(GDP)
```

```{r}
global_economy |> 
  filter(Country == "Australia") |> 
  autoplot(GDP / Population)
```

```{r}
print_retail <- aus_retail |> 
  filter(Industry == "Newspaper and book retailing") |> 
  group_by(Industry) |> 
  index_by(Year = year(Month)) |> 
  summarise(Turnover = sum(Turnover))
```

```{r}
aus_economy <- global_economy |> 
  filter(Code == "AUS")
```

```{r}
print_retail |> 
  left_join(aus_economy) |> 
  mutate(Adjusted_turnover = Turnover / CPI * 100) |> 
  pivot_longer(c(Turnover, Adjusted_turnover),
               values_to = "Turnover") |> 
  mutate(name = factor(name, 
                       levels = c("Turnover", "Adjusted_turnover"))) |> 
  ggplot(aes(x = Year, y = Turnover)) +
  geom_line() +
  facet_grid(name ~ ., scales = "free_y") +
  labs(title = "Turnover: Australian print media history",
       y = "$AU")
  
```

Mathematical transformations: if the data show different variation at different levels of the series, then a transformation can be useful.

Denote original observations as $y_1$, ..., $y_T$ and transformed observations as $w_1$, ... $w_T$.

e.g. square root, cube root, logarithm

```{r}
food <- aus_retail |> 
  filter(Industry == "Food retailing") |> 
  summarise(Turnover = sum(Turnover))
```

```{r}
food |> 
  autoplot(Turnover) +
  labs(y = "Turnover ($AUD)")
```

```{r}
food |> 
  autoplot(sqrt(Turnover)) +
  labs(y = "Square root turnover")
```

```{r}
food |> 
  autoplot(log(Turnover)) +
  labs(y = "Log turnover")
```

```{r}
food |> 
  autoplot(-1 / Turnover) +
  labs(y = "Inverse turnover")
```

Box-Cox transformations

```{r}
food |> 
  features(Turnover, features = guerrero)
```

-   This attempts to balance the seasonal fluctuations and random variation across the series

-   Always check the results

-   A low value of $\lambda$ can give extremely large prediction intervals

```{r}
food |> 
  autoplot(box_cox(Turnover, 0.0524)) +
  labs(y = "Box-Cox transformed turnover")
```

-   Often no transformation needed

-   Simple transformations are easier to explain and work well enough

-   Transformations can have very large effect on Prediction Intervals (PI)

-   If some data are zero or negative, then use $\lambda$ \> 0

-   `log1p()` can also be useful for data with zeros

-   Choosing logs is a simple way to force forecasts to be positive

-   Transformations must be reversed to obtain forecasts on the original scale (handled automatically by `fable`)

# 3.2 Time series components

-   **Trend**: pattern exists when there is a long-term increase or decrease in the data.

-   **Cyclic**: pattern exists when data exhibit rises and falls that are not of fixed period (duration usually of at least 2 years)

-   **Seasonal**: pattern exists when a series is influenced by seasonal factors (e.g. the quarter of the year, the month, or day of the week)

$$
y_t=f(S_t,T_t,R_t)
$$

where:

-   $y_t$=data at period t

-   $T_t$=trend-cycle component at period t

-   $S_t$=seasonal component at period t

-   $R_t$=remainder component at period t

Additive decomposition: $y_t=S_t+T_t+R_t$

Multiplicative decomposition: $y_t=S_t \times T_t \times R_t$

-   Additive model appropriate if magnitude of seasonal fluctuations does not vary with level

-   If seasonal are proportional to level of series, then multiplicative model appropriate

-   Multiplicative decomposition more prevalent with economic series

-   Alternative: use a Box-Cox transformation, and then use additive decomposition

-   Logs turn multiplicative relationship into an additive relationship:

$$
y_t=S_t \times T_t \times R_t
$$

$$
log(y_t)=log(S_t)+log(T_t)+log(R_t)
$$

```{r}
us_retail_employment <- us_employment |> 
  filter(year(Month) >= 1990, Title == "Retail Trade") |> 
  select(-Series_ID)
us_retail_employment
```

```{r}
us_retail_employment |> 
  autoplot(Employed) +
  labs(y = "Persons (thousands)",
       title = "Total employment in US retail")
```

```{r}
us_retail_employment |> 
  model(stl = STL(Employed))
```

```{r}
dcmp <- us_retail_employment |> 
  model(stl = STL(Employed))
components(dcmp)
```

```{r}
components(dcmp) |> autoplot()
```

```{r}
us_retail_employment |> 
  autoplot(Employed, color = "gray") +
  autolayer(components(dcmp), trend, color = "#D55E00") +
  labs(y = "Persons (thousands)",
       title = "Total employment in US retail")
```

```{r}
components(dcmp) |> gg_subseries(season_year)
```

Seasonal adjustment:

-   useful by-product of decomposition: an easy way to calculate seasonally adjusted data

-   additive decomposition: seasonally adjusted data given by

    $$
    y_t-S_t=T_t+R_t
    $$

-   Multiplicative decomposition: seasonally adjusted data given by

    $$
    y_t/S_t=T_t \times R_t
    $$

```{r}
us_retail_employment |> 
  autoplot(Employed, color = "gray") +
  autolayer(components(dcmp), season_adjust, color = "#0072B2") +
  labs(y = "Persons (thousands)",
       title = "Total employment in US retail")
```

-   We use estimates of $S$ based on past values to seasonally adjust a current value

-   Seasonally adjusted series reflect **remainders** as well as **trend**. Therefore they are not "smooth" and "downturns" or "upturns" can be misleading

-   It is better to use the trend-cycle component to look for turning points

# 3.3 Moving averages

The simplest estimate of the trend-cycle uses **moving averages**

$$
\hat{T}_t=\frac{1}{m} \sum_{j=-k}^k y_{t+j}
$$

where $k=\frac{m-1}{2}$

```{r}
global_economy |> 
  filter(Country == "Australia") |> 
  autoplot(Exports) +
  labs(y = "% of GDP", title = "Total Australian exports")
```

So a moving average is an average of nearby points

-   observations nearby in time are also likely to be close in value.
-   average eliminates some randomness in the data, leaving a smooth trend-cycle component.

3-MA and 5-MA: $$
\hat{T}_t = (y_{t-1} + y_{t} + y_{t+1})/3
$$
$$
\hat{T}_t = (y_{t-2} + y_{t-1} + y_{t} + y_{t+1} + y_{t+2})/5
$$

-   each average computed by dropping oldest observation and including next observation.
-   averaging moves through time series until trend-cycle computed at each observation possible.

Why is there no estimate at ends?

-   For a 3 MA, there cannot be estimates at time 1 or time T because the observations at time 0 and T + 1 are not available

-   Generally: there cannot be estimates at times near the endpoints

The order of the MA

-   larger order means smoother, flatter curve

-   larger order means more points lost at ends

-   order = length of season or cycle removes pattern

-   but so far odd orders?

```{r}
aus_exports <- global_economy |>
  filter(Country == "Australia") |>
  mutate(
    `5-MA` = slider::slide_dbl(Exports, mean,
                .before = 2, .after = 2, .complete = TRUE)
  )
```

```{r}
aus_exports |>
  autoplot(Exports) +
  geom_line(aes(y = `5-MA`), colour = "#D55E00") +
  labs(y = "% of GDP",
       title = "Total Australian exports")
```

```{r}
us_retail_employment_ma <- us_retail_employment |>
  mutate(
    `12-MA` = slider::slide_dbl(Employed, mean,
                .before = 5, .after = 6, .complete = TRUE),
    `2x12-MA` = slider::slide_dbl(`12-MA`, mean,
                .before = 1, .after = 0, .complete = TRUE)
  )
us_retail_employment_ma |>
  autoplot(Employed, colour = "gray") +
  geom_line(aes(y = `2x12-MA`), colour = "#D55E00") +
  labs(y = "Persons (thousands)",
       title = "Total employment in US retail")
```

# 3.4 Classical decomposition
